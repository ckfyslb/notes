### 1. `llamaindex`问题

#### (1) 导入 `HuggingFaceEmbedding` 报错

```python
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
```

导入`HuggingFaceEmbedding`报错：

```shell
CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcudart.so.11.0
CUDA SETUP: Highest compute capability among GPUs detected: 8.0
CUDA SETUP: Detected CUDA version 118
CUDA SETUP: Loading binary /home/.conda/envs/qwen/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...
/lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by /home/.conda/envs/qwen/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so)
CUDA SETUP: Something unexpected happened. Please compile from source:
git clone git@github.com:TimDettmers/bitsandbytes.git
cd bitsandbytes
CUDA_VERSION=118 make cuda11x
python setup.py install
```

根据报错提示信息操作，未解决：

1. `git clone`

报错给的仓库 https://github.com/TimDettmers/bitsandbytes.git 不存在，在`github`搜索`bitsandbytes`找到仓库

2. `cd bitsandbytes`
3. `CUDA_VERSION=118 make cuda11x`

报错：

```shell
make: *** 没有规则可以创建目标“cuda11x”。 停止。
```

4. `python setup.py install`

==解决：==

执行`pip show bitsandbytes`查看`bitsandbytes`所在位置

执行`vim ~/.bash_profile`打开`.bash_profile`，
添加环境变量`export LD_LIBRARY_PATH=/home/.conda/envs/qwen/lib/python3.8/site-packages/:$LD_LIBRARY_PATH`

执行`source ~/.bash_profile`使文件更新生效

> [解决CUDA环境配置中的`libcudart.so`缺失问题-百度开发者中心 (baidu.com)](https://developer.baidu.com/article/details/3264277)
>
> [大模型训练时，使用bitsandbytes报错的解决方法-CSDN博客](https://blog.csdn.net/anycall201/article/details/129930919)

#### (2) `llamaindex` 解析文档报错

使用`llamaindex`解析文档时报错，无法连接`OpenAI`

`llamaindex`会默认连接`OpenAI`

```shell
ValueError: 
******
Could not load OpenAI model. If you intended to use OpenAI, please check your OPENAI_API_KEY.
Original error:
No API key found for OpenAI.
Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.
API keys can be found or created at https://platform.openai.com/account/api-keys

To disable the LLM entirely, set llm=None.
******
```

==解决：==

设置大模型和`Embedding`模型

```python
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.huggingface import HuggingFaceLLM
from llama_index.core import Settings

Settings.embed_model = HuggingFaceEmbedding(model_name = 'sentence-transformers/all-MiniLM-L6-v2', device = 'cuda')
Settings.llm = HuggingFaceLLM(model_name="/home/qwen/Qwen2-7B-Instruct")
```

#### (3) 连接`huggingface`报错

使用`llama_index`中的`huggingface`接口设置大语言模型和`Embedding`模型为本地模型，运行时出现无法连接`huggingface.co`的错误，由于`huggingface`会默认从`huggingface`官网缓存模型文件

==解决：==

设置环境变量`export HF_ENDPOINT=https://hf-mirror.com`，从镜像网站缓存

#### (4) `UnstructuredElementNodeParser` 报错

运行`get_nodes_from_documents`时报错

```python
node_parser = UnstructuredElementNodeParser()
raw_nodes = node_parser.get_nodes_from_documents(xuqiu_file)
```

```shell
RuntimeError: Detected nested async. Please use nest_asyncio.apply() to allow nested event loops.Or, use async entry methods like `aquery()`, `aretriever`, `achat`, etc.
```

==解决：==

```python
import nest_asyncio
nest_asyncio.apply()
```



### 2. `flash_attn` 版本问题

```shell
RuntimeError: Failed to import transformers.models.qwen2.modeling_qwen2 because of the following error (look up to see its traceback):
/home/.conda/envs/qwen/lib/python3.8/site-packages/flash_attn_2_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
```

`flash_attn`版本问题，安装的`2.6.2`版本在`python3.8`上不能使用，在[flash-attention下载地址](https://github.com/Dao-AILab/flash-attention/releases/)中找到适合`python3.8（cuda11.8+torch2.1）`的最新版本是`flash_attn 2.6.1`

==解决：==

```shell
#下载（服务器连接不上github，手动下载后传到服务器再安装）
wget https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.1/flash_attn-2.6.1+cu118torch2.1cxx11abiFALSE-cp38-cp38-linux_x86_64.whl
# pip安装
pip install flash_attn-2.6.1+cu118torch2.1cxx11abiFALSE-cp38-cp38-linux_x86_64.whl
```

>cxx11abiFALSE与cxx11abiTRUE的区别：
>
>有些`Pytorch wheels`编译时使用`-D_GLIBCXX_USE_CXX11_ABI=0`(例如从`pytorch.org`下载)，有些编译时使用`-D_GLIBCXX_USE_CXX11_ABI=1`(例如从`nvcr docker image`)。`FlashAttention`是一个`Pytorch`扩展，所以有2个不同的`wheels`可选。可通过检查`torch._C._GLIBCXX_USE_CXX11_ABI`下载与本地`Pytorch`版本兼容的选项。

```python
>>> import torch
>>> torch._C._GLIBCXX_USE_CXX11_ABI
False
```

> [FlashAttention（flash-attn）安装_flash-attn安装-CSDN博客](https://blog.csdn.net/MurphyStar/article/details/138523803)



### 3. `linux` 字符集问题

```shell
-bash: 警告:setlocale: LC_TIME: 无法改变区域选项 (zh_CN.UTF-8) 
-bash: 警告:setlocale: LC_ALL: 无法改变区域选项 (en_US.UTF-8): 没有那个文件或目录 
-bash: 警告:setlocale: LC_ALL: 无法改变区域选项 (en_US.UTF-8)
```

>  [解决问题 setlocale: LC_ALL: cannot change locale (en_US.UTF-8): No such file or directory - 一只小小的寄居蟹 - 博客园 (cnblogs.com)](https://www.cnblogs.com/xiao-apple36/p/17047135.html)



### 4. 误删 `libc.so.6` 修复

在秘服务器安装`LibreOffice_24.2.6`时，`glibc`库版本过低，需要升级`libc.so.6`和`libm.so.6`，升级时误删除或强制链接`libc.so.6`都会导致很多命令用不了，重启无法开机。

> `glibc`是`Linux`系统中最底层的`api`，`Linux`几乎所有运行库都依赖`glibc`。`/usr/lib64/libc.so.6`属于`glibc`，在`centos7`中是个软链接。
>
> 一旦误删或误操作`libc.so.6`，或者`glibc`新版本不兼容等原因，都可能导致很多命令不可用、不能连接系统、系统崩溃、无法开机等问题。

==解决：==

1. 使用软碟通制作系统光盘；

2. 开机设置`bios`由光盘启动；

3. 选择 `troubleshooting`，然后`rescue a centos system`，进入救援模式；

4. 进入终端，原系统的目录被`mount`到了`/mnt/sysimage`下；

5. 进入系统数据的库文件目录下

   ```shell
   cd /mnt/sysimage/usr/lib64
   ```

6. 恢复原软链接（若`ln -s`不能使用，则使用`sln`）

   ```shell
   ln -s libc-2.17.so libc.so.6
   ```

7. 重启，完成修复。

> [业内同行盆友来稿：对libc.so下毒手引发的惨痛血案，围观大型翻车现场...-CSDN博客](https://blog.csdn.net/ttropsstack/article/details/125380630)
>
> [linux系统救援模式拯救mv libc.so.6文件后无法使用命令的悲剧 - lao顽童 - 博客园 (cnblogs.com)](https://www.cnblogs.com/hsjy/p/9056276.html)
>
> [误删除libc.so.6 恢复 - 邱明成 - 博客园 (cnblogs.com)](https://www.cnblogs.com/qiumingcheng/p/11152885.html)
>
> [【Linux】解决误操作libc.so.6导致的问题，补充：升级glibc注意事项_linux_yannan20190313-Linux (csdn.net)](https://devpress.csdn.net/linux/66d01625a1ed2f4c853ebb62.html)



### 5. 使用指定的 `GPU`

服务器有2张卡，但是只能识别到1张，设置`cuda`使用第2个设备报错

==解决：==

```shell
# 在.bashrc末尾加上:
export CUDA_VISIBLE_DEVICE="0,1"

# 然后执行
source ~/.bashrc
```

然后就可以设置`cuda`了：

```python
import torch
torch.cuda.set_device(1)
```

或

```python
import os
os.environ["CUDA_VISIBLE_DEVICES"]="1"
```

> [服务器有多张GPU可Pytorch中却只能检测到一张卡（several GPUs, only one can be detected）_我服务器有两块gpu怎么在cuda里面显示一块-CSDN博客](https://blog.csdn.net/jzwong/article/details/103813999#:~:text=简单地说，就是你需要在自己的.bashrc文件中进行声明一下，参考如下截图： 如果你是两张卡，对应就在.bashrc末尾加上export,CUDA_VISIBLE_DEVICES %3D0%2C1摸着葫芦画瓢即可。)



### 6. 量化模型问题

**>>> 1**

`Qwen2.5`量化模型推理速度很慢（例如`Qwen2.5-72B-Instruct-GPTQ-Int4`），同时提示`CUDA extension not installed`。

解决：

1. 降低`auto-gptq`版本。

   ```shell
   pip uninstall auto-gptq
   pip install auto-gptq==0.6.0 (要安装的版本)
   ```

2. 或者从源码安装`auto-gptq`：

   ```shell
   git clone https://github.com/PanQiWei/AutoGPTQ.git && cd AutoGPTQ
   
   pip install -vvv --no-build-isolation -e .
   ```

   > [AutoGPTQ/README.md at main · AutoGPTQ/AutoGPTQ](https://github.com/AutoGPTQ/AutoGPTQ/blob/main/README.md)

**>>> 2**

继续报错：

```shell
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect. 
For debugging consider passing CUDA_LAUNCH_BLOCKING=1 
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
```

设置`CUDA_LAUNCH_BLOCKING=1`、`TORCH_USE_CUDA_DSA=1`，以及设置`device`为`cpu`后获得具体错误：

```shell
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
```

尝试解决：

1. 加载模型时，将`torch_dtype="auto"`改为`torch_dtype="bfloat16"或"float32"`：

```python
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="bfloat16",
    device_map="auto"
)
```

> 在模型的`config.json`文件中`torch_dtype`默认为`"float16"`

不报错了，但是输出乱码。

2. 网上说设置环境变量后重新构建`pytorch`，没尝试。
2. ==解决办法：==  来自：https://github.com/QwenLM/Qwen2.5/issues/102#issuecomment-2177908094

对于 `GPTQ-Int8` 模型：

- 在`modelscope`下载模型，使用`transformers`加载和运行模型; 确保`auto-gptq`被正确安装；  [无效]

- 使用 `vllm` 替代 `transformers + auto-gptq`；  ==[解决]==      :joy::joy::joy:

- 使用`fp32` 替代 `fp16` (`bf16`不会起作用)。  [无效]

**>>> 3**

使用 `vllm` 后，模型输出后产生警告：

```shell
[rank0]:[W1114 16:38:26.924830158 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present, but this warning has only been added since PyTorch 2.4 (function operator())

[rank0]：[W1114 16：38：26.924830158 ProcessGroupNCCL.cpp：1250] 警告：警告：在我们销毁 ProcessGroupNCCL 之前，进程组尚未被销毁。在正常程序退出时，应用程序应调用 destroy_process_group 以确保在此过程中已完成任何挂起的 NCCL 操作。在极少数情况下，此进程可能会在此点之前退出，并阻止进程组的其他成员的进度。此约束一直存在，但此警告仅在 PyTorch 2.4 （function operator（）） 后添加
```

大模型给出解答：

```python
import torch.distributed as dist

# 假设您已经初始化了进程组
dist.init_process_group(backend='nccl')

# 在程序正常退出之前销毁进程组
dist.destroy_process_group()
```

> [没尝试，忽略此警告]



### 7. 模型长文本问题

模型的上下文长度默认最多为`32,768`个`tokens`。为了处理超过`32,768`个`tokens`的输入，使用`YaRN`确保在长文本上的最佳性能。 

在`Qwen2.5-72B-Instruct-GPTQ-Int4`的`config.json`加入：

```json
{
  ...,
  "rope_scaling": {
    "factor": 4.0,
    "original_max_position_embeddings": 32768,
    "type": "yarn"
  }
}
```

运行模型报错：

```shell
Unrecognized keys in `rope_scaling` for 'rope_type'='yarn': {'original_max_position_embeddings'}
```

\- 这个错误信息表明在 `rope_scaling` 配置中，有一个键 `original_max_position_embeddings` 对于 `rope_type='yarn'`是不被识别的。

\- `rope_scaling` 是用于调整模型中的 `RoPE（Rotary Position Embedding）`的配置。`RoPE`是一种用于处理长序列的方法，通常用于大型语言模型中。

升级`transformers`到最新版，未解决。

==从`config.json`删去了`rope_scaling`。==



### 8. 容器内无法使用GPU

**(1) 安装 NVIDIA 容器工具包**

```bash
sudo yum install -y nvidia-container-toolkit
```

**(2) 配置 Docker 使用 NVIDIA 运行时**

```bash
# 生成默认配置
sudo nvidia-ctk runtime configure --runtime=docker

# 重启 Docker 服务
sudo systemctl restart docker
```

**(3) 验证配置**

```bash
sudo docker info | grep -i runtime
```



### 9. Ragflow 和 Dify 的端口冲突

1）`Nginx`都使用 80 和 443 端口

> ==解决==：修改 Dify 的.env 文件中的端口为 8080 和 4443

2）`Redis`都使用 6379 端口

当两个服务都启动后，其中一个服务的 Redis 容器会被删除，导致该服务无法正常访问。

> **未解决：修改其中一个项目使用的 Redis 端口**

问题原因：Docker Compose 未指定项目名称。Docker Compose 使用**项目名称**来隔离不同的项目环境。默认情况下，项目名称是 docker-compose.yml 文件所在目录的名称。由于 Ragflow 和 Dify 的 docker-compose.yml 文件都位于各自项目目录的 docker/ 目录下，导致两个服务的容器未能被有效隔离，从而引发冲突。

> ==解决==：在 dify 项目的 docker/ 目录下通过 `-p` 指定项目名称启动服务
>
> ```shell
> docker compose -f docker-compose.yaml -p dify up -d
> ```

实际上 `ragflow` 的 `redis` 容器将容器内部的 6379 端口映射到了主机的 6379 端口。而 `dify` 的 `redis` 容器只暴露了容器内部的 6379 端口，但没有映射到主机端口（`6379/tcp` 表示仅容器内部使用）。因此两者的端口并不会冲突。

> 参考：
>
> 1. [一台服务器同时启动RagFlow和Dify，Redis冲突的解决办法 - 知乎](https://zhuanlan.zhihu.com/p/1890725185272907308)
> 2. [实测有效！一台服务器上同时启动Dify和Ragflow时，redis容器冲突解决方法。_dify和ragflow端口冲突-CSDN博客](https://blog.csdn.net/weixin_44341746/article/details/145176016)
